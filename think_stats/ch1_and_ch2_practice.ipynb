{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef808d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40033a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>shelf</th>\n",
       "      <th>weight</th>\n",
       "      <th>cups</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106.883117</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>1.012987</td>\n",
       "      <td>159.675325</td>\n",
       "      <td>2.151948</td>\n",
       "      <td>14.597403</td>\n",
       "      <td>6.922078</td>\n",
       "      <td>96.077922</td>\n",
       "      <td>28.246753</td>\n",
       "      <td>2.207792</td>\n",
       "      <td>1.029610</td>\n",
       "      <td>0.821039</td>\n",
       "      <td>42.665705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.484119</td>\n",
       "      <td>1.094790</td>\n",
       "      <td>1.006473</td>\n",
       "      <td>83.832295</td>\n",
       "      <td>2.383364</td>\n",
       "      <td>4.278956</td>\n",
       "      <td>4.444885</td>\n",
       "      <td>71.286813</td>\n",
       "      <td>22.342523</td>\n",
       "      <td>0.832524</td>\n",
       "      <td>0.150477</td>\n",
       "      <td>0.232716</td>\n",
       "      <td>14.047289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>18.042851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>33.174094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>40.400208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.828392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>93.704912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calories    protein        fat      sodium      fiber      carbo  \\\n",
       "count   77.000000  77.000000  77.000000   77.000000  77.000000  77.000000   \n",
       "mean   106.883117   2.545455   1.012987  159.675325   2.151948  14.597403   \n",
       "std     19.484119   1.094790   1.006473   83.832295   2.383364   4.278956   \n",
       "min     50.000000   1.000000   0.000000    0.000000   0.000000  -1.000000   \n",
       "25%    100.000000   2.000000   0.000000  130.000000   1.000000  12.000000   \n",
       "50%    110.000000   3.000000   1.000000  180.000000   2.000000  14.000000   \n",
       "75%    110.000000   3.000000   2.000000  210.000000   3.000000  17.000000   \n",
       "max    160.000000   6.000000   5.000000  320.000000  14.000000  23.000000   \n",
       "\n",
       "          sugars      potass    vitamins      shelf     weight       cups  \\\n",
       "count  77.000000   77.000000   77.000000  77.000000  77.000000  77.000000   \n",
       "mean    6.922078   96.077922   28.246753   2.207792   1.029610   0.821039   \n",
       "std     4.444885   71.286813   22.342523   0.832524   0.150477   0.232716   \n",
       "min    -1.000000   -1.000000    0.000000   1.000000   0.500000   0.250000   \n",
       "25%     3.000000   40.000000   25.000000   1.000000   1.000000   0.670000   \n",
       "50%     7.000000   90.000000   25.000000   2.000000   1.000000   0.750000   \n",
       "75%    11.000000  120.000000   25.000000   3.000000   1.000000   1.000000   \n",
       "max    15.000000  330.000000  100.000000   3.000000   1.500000   1.500000   \n",
       "\n",
       "          rating  \n",
       "count  77.000000  \n",
       "mean   42.665705  \n",
       "std    14.047289  \n",
       "min    18.042851  \n",
       "25%    33.174094  \n",
       "50%    40.400208  \n",
       "75%    50.828392  \n",
       "max    93.704912  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cereal.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d08b1b",
   "metadata": {},
   "source": [
    "## high level analysis\n",
    "\n",
    "thre are 77 cereals represented here, no missing values across all variables. \n",
    "is there a codebook for this? yeah more or less it is the summary on kaggle: \n",
    "\n",
    "Fields in the dataset:\n",
    "\n",
    "Name: Name of cereal\n",
    "mfr: Manufacturer of cereal\n",
    "A = American Home Food Products;\n",
    "G = General Mills\n",
    "K = Kelloggs\n",
    "N = Nabisco\n",
    "P = Post\n",
    "Q = Quaker Oats\n",
    "R = Ralston Purina\n",
    "type:\n",
    "cold\n",
    "hot\n",
    "calories: calories per serving\n",
    "protein: grams of protein\n",
    "fat: grams of fat\n",
    "sodium: milligrams of sodium\n",
    "fiber: grams of dietary fiber\n",
    "carbo: grams of complex carbohydrates\n",
    "sugars: grams of sugars\n",
    "potass: milligrams of potassium\n",
    "vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended\n",
    "shelf: display shelf (1, 2, or 3, counting from the floor)\n",
    "weight: weight in ounces of one serving\n",
    "cups: number of cups in one serving\n",
    "rating: a rating of the cereals (Possibly from Consumer Reports?)\n",
    "\n",
    "questions I have initially: \n",
    "- are the less healthy cereals stocked on a particular shelf relative to teh others? \n",
    "- do the same cereals that are low in sugar also have more vitamins? \n",
    "- what do the ratings mean? does that correlate to low sugar, high vitamin content, or something else?\n",
    "- are cereals with high sugar content heavier or lighter per ounce? is there any relationship? \n",
    "- are serving sizes manipulated to keep the sugar levels down in cereals that we know have more sugar overall? do we even have enough information to know this? \n",
    "\n",
    "### using what I've learned: \n",
    "\n",
    "- standard deviation of calories is about 20, \n",
    "    so a cereal that is more than 40 calories from the mean of 106 in either direction is likely an outlier \n",
    "- similar for sugars in grams, 9 grams more or less than about 7 so more than 16 at least we know would be an extreme value, can't be 9 lower than 7,    but values close to 0 would be surprising. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a1d85",
   "metadata": {},
   "source": [
    "## examining variables one by one first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9628b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency tables and distribution plots shall we? \n",
    "import thinkstats\n",
    "\n",
    "# just look around first\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d659649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean carbs for each\n",
      "more sugar: 12.711538461538462\n",
      "less sugar: 15.558823529411764\n",
      " difference in average carb content between more sugar and less sugar groups -2.847285067873303\n",
      "ok so that was the absolute effect size, average carb quantity almost 3 grams higher for the lower sugar group\n",
      "how about for relative effect size? this would be -19.50542261799327%\n"
     ]
    }
   ],
   "source": [
    "# lets look at the items by descending sugar content, spot anomolous values\n",
    "df[\"sugars\"].value_counts().sort_index()\n",
    "\n",
    "lots_of_sugar = df.query(\"sugars >= 10\")\n",
    "less_sugar = df.query(\"sugars < 10\")\n",
    "\n",
    "difference_in_carbs = lots_of_sugar[\"carbo\"].mean() - less_sugar[\"carbo\"].mean()\n",
    "\n",
    "print(\"mean carbs for each\")\n",
    "print(f\"more sugar: {lots_of_sugar['carbo'].mean()}\")\n",
    "print(f\"less sugar: {less_sugar['carbo'].mean()}\")\n",
    "\n",
    "print(f\" difference in average carb content between more sugar and less sugar groups {difference_in_carbs}\")\n",
    "print(f\"ok so that was the absolute effect size, average carb quantity almost 3 grams higher for the lower sugar group\")\n",
    "print(f\"how about for relative effect size? this would be {difference_in_carbs / df[\"carbo\"].mean() * 100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558acca",
   "metadata": {},
   "source": [
    "### ok it appears as though the higher sugar cereals have fewer carbs on average, maybe cohen's effect would help here. \n",
    "\n",
    "I think cohen's effect is necessary here for the same reason it was necessary in the question of whetehr first born or later born children are born later. we have two groups now, each with their own mean and spread. \n",
    "\n",
    "so what we have going on is there is a very real quantitative signal coming from the data. it is not fully causal, because there could be more explanations for why there are more carbs by ~3 grams on average coming from the less sugary cereals, but those explanations woudl be coming from outside the dataset. as far as this sample is concerned, we are seeing something show up at least for the way we grouped these things. \n",
    "\n",
    " we've shown absolute difference with the difference in averages, and relative difference with the 19% difference between the groups, what about    \n",
    "\n",
    "\n",
    " getting this from wikipedia and then a follow up question which really helped me understand why having a large standard deviation when you are comparing averages could make it hard to distinguish signal and noise\n",
    "\n",
    " Understanding Why Large Standard Deviations Undercut Effect Size Claims\n",
    "The intuition behind why a large standard deviation diminishes the meaningfulness of an effect size comes down to signal-to-noise ratio. Let me explain:\n",
    "\n",
    "The Signal-to-Noise Problem\n",
    "When we measure an effect size (like the difference between high-sugar and low-sugar cereals' carb content), we're essentially asking: \"How strong is this signal compared to the background noise?\"\n",
    "\n",
    "If we have:\n",
    "\n",
    "A small effect (small difference between means)\n",
    "And a large standard deviation (high variability within groups)\n",
    "Then our effect becomes harder to distinguish from random variation.\n",
    "\n",
    "Visual Intuition\n",
    "Imagine two scenarios measuring the same effect:\n",
    "\n",
    "Scenario 1: Small standard deviation\n",
    "Groups are clearly separated\n",
    "The difference is obvious and meaningful\n",
    "Effect size will be large (e.g., Cohen's d = 2.0)\n",
    "Scenario 2: Large standard deviation\n",
    "Groups overlap substantially\n",
    "The difference exists but is less meaningful\n",
    "Effect size will be small (e.g., Cohen's d = 0.5)\n",
    "Why This Matters\n",
    "Practical significance: If your measurements vary widely within groups (large SD), then knowing which group something belongs to doesn't help much in predicting its value.\n",
    "\n",
    "Statistical reliability: Large standard deviations indicate more uncertainty in your measurements, making it harder to conclude the effect is real rather than random noise.\n",
    "\n",
    "Decision-making value: If you're using the effect to make decisions (like choosing cereal types), a small effect lost in high variability isn't very helpful for predictions.\n",
    "\n",
    "In Your Cereal Analysis\n",
    "When comparing high-sugar vs. low-sugar cereals, the meaningfulness of the ~3g carbohydrate difference depends on how variable carbs are within each group. If the standard deviation within each group is, say, 10g, then the 3g difference isn't very informative - many high-sugar cereals will still have more carbs than some low-sugar cereals.\n",
    "\n",
    "The Cohen's effect size calculation handles this by standardizing the mean difference relative to the pooled standard deviation, giving you a clearer picture of how meaningful the difference actually is in the context of the natural variation in your data.\n",
    "\n",
    "say in your own words: \n",
    "- ok so effect size. say you have two things, in this case it is amount of sugar and amount of carbs in cereal. it could be any two variables that show some numerical value about something. maybe it is how many home runs a baseball player had, maybe it is how many hit points of life a pokemon has, maybe it is how many times I've been to the moon. so you take two of these things across a population. so like how long are the hairs for the population of all the world's cats? or maybe how many people who watched movies in 2025 have gone to watch lilo and stitch. then you take another measurement of another attribute of the same population, say the number of people who watched movies in 2025 who watched the final destination movie. you want to compare those two attributes of the population. but you shoudl also know that it doesn't have to be across attributes, it can be within them too. you can also be between \"of all the people living in my city, the number of kids that the group with more than 100,000 yearly income have and the number of kids that the group with less than 100,000 yearly income have. The effect is something you use to represent how strongly related these things are and the effect size is the actual size of the difference between them. \n",
    "\n",
    "- given that iw what effects are trying to do, in this case answer the question \"what is the strength of the relationship between how high carbohydrate content is in a cereal overall and how much sugar that cereal contains?\" we first take our data, all the cereal, then we decide what the variables will be, and we get to carbohydrate in cereal with more than 10g sugar per serving and carbohydrate in cereal with less than 10g sugar per serving.  Maybe there were other ways to compare sugar and carb content which are more holistic, now that I think about it. could I have chosen to just average the carb content overall and the sugar content overall to see if there was a relationship? sure I could have, but what that would have told me more is how much the overall carb content and sugar content are related, like do the cereals have more sugar than carbs overall? by not bisecting and comparing the sugar groups I'm asking a different question. Getting at the fact that these are actually betweeen two different variables, the sugar quantity and the carbohydrate quantity, whereas my original was comparing one variable's amount (amount of carbs) betweeen two groups within another variable (cereals with more sugar and cereals with less). and that is the difference between something like cohen's effect or cohen's d and pearson's correlation. teh former is about group comparison and the latter is about variables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mfr</th>\n",
       "      <th>type</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>fiber</th>\n",
       "      <th>carbo</th>\n",
       "      <th>sugars</th>\n",
       "      <th>potass</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>shelf</th>\n",
       "      <th>weight</th>\n",
       "      <th>cups</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Quaker Oatmeal</td>\n",
       "      <td>Q</td>\n",
       "      <td>H</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>50.828392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name mfr type  calories  protein  fat  sodium  fiber  carbo  \\\n",
       "57  Quaker Oatmeal   Q    H       100        5    2       0    2.7   -1.0   \n",
       "\n",
       "    sugars  potass  vitamins  shelf  weight  cups     rating  \n",
       "57      -1     110         0      1     1.0  0.67  50.828392  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sugars\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d04a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        Quaker Oatmeal\n",
       "mfr                      Q\n",
       "type                     H\n",
       "calories               100\n",
       "protein                  5\n",
       "fat                      2\n",
       "sodium                   0\n",
       "fiber                  2.7\n",
       "carbo                  1.0\n",
       "sugars                   1\n",
       "potass                 110\n",
       "vitamins                 0\n",
       "shelf                    1\n",
       "weight                 1.0\n",
       "cups                  0.67\n",
       "rating           50.828392\n",
       "Name: 57, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quaker appears to be bad data, not sure but seems to be, maybe I can fix by imputing correct amount for quaker that I lookup online since it is just the one example\n",
    "# also this data sseems inconsistent with what I found online drawing thw whole thing into suspicion\n",
    "# anyway, let's change this to 1\n",
    "\n",
    "\n",
    "df_cleaned = df.copy(deep=True)\n",
    "df_cleaned.at[57, \"sugars\"] = 1\n",
    "df_cleaned.at[57, \"carbo\"] = 1\n",
    "\n",
    "df_cleaned.iloc[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fdeac49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fat\n",
       "1    30\n",
       "0    27\n",
       "2    14\n",
       "3     5\n",
       "5     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"fat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09735a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carbo\n",
       "1.0     1\n",
       "5.0     1\n",
       "7.0     1\n",
       "8.0     2\n",
       "9.0     1\n",
       "10.0    2\n",
       "10.5    2\n",
       "11.0    5\n",
       "11.5    1\n",
       "12.0    7\n",
       "13.0    8\n",
       "13.5    1\n",
       "14.0    7\n",
       "15.0    8\n",
       "16.0    7\n",
       "17.0    6\n",
       "18.0    3\n",
       "19.0    1\n",
       "20.0    3\n",
       "21.0    7\n",
       "22.0    2\n",
       "23.0    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at these\n",
    "df_cleaned[\"carbo\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2024ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name mfr type  calories  protein  fat  sodium  fiber  \\\n",
      "14           Cocoa Puffs   G    C       110        1    1     180    0.0   \n",
      "18         Count Chocula   G    C       110        1    1     180    0.0   \n",
      "24           Froot Loops   K    C       110        2    1     125    1.0   \n",
      "46  Mueslix Crispy Blend   K    C       160        3    2     150    3.0   \n",
      "\n",
      "    carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n",
      "14   12.0      13      55        25      2     1.0  1.00  22.736446  \n",
      "18   12.0      13      65        25      2     1.0  1.00  22.396513  \n",
      "24   11.0      13      30        25      2     1.0  1.00  32.207582  \n",
      "46   17.0      13     160        25      3     1.5  0.67  30.313351  \n",
      "         name mfr type  calories  protein  fat  sodium  fiber  carbo  sugars  \\\n",
      "61  Rice Chex   R    C       110        1    0     240    0.0   23.0       2   \n",
      "\n",
      "    potass  vitamins  shelf  weight  cups     rating  \n",
      "61      30        25      1     1.0  1.13  41.998933  \n"
     ]
    }
   ],
   "source": [
    "# slow and deliberate comparison, showing that most unhealthy cereals in terms of sugars aren't necessarily the highest carb cereals\n",
    "print(df[df[\"sugars\"] == 13])\n",
    "print(df[df[\"carbo\"] == 23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09951c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_carb = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
